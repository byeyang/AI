{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集: 某外卖平台收集的用户评价，正向 4000 条，负向 约 8000 条"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字段说明\n",
    "\n",
    "| 字段 | 说明 |\n",
    "| ---- | ---- |\n",
    "| label | 1 表示正向评论，0 表示负向评论 |\n",
    "| review | 评论内容 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装 jieba 和 pandas\n",
    "\n",
    "     pip install pandas jieba sklearn -i https://pypi.doubanio.com/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('waimai_10k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>很快，好吃，味道足，量大</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>没有送水没有送水没有送水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>非常快，态度好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>方便，快捷，味道可口，快递给力</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>菜味道很棒！送餐很及时！</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label           review\n",
       "0      1     很快，好吃，味道足，量大\n",
       "1      1     没有送水没有送水没有送水\n",
       "2      1         非常快，态度好。\n",
       "3      1  方便，快捷，味道可口，快递给力\n",
       "4      1     菜味道很棒！送餐很及时！"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11987 entries, 0 to 11986\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   11987 non-null  int64 \n",
      " 1   review  11987 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 187.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7987\n",
       "1    4000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_text(text):\n",
    "    text = text.replace('！', '').replace('，', '').replace('。', '')\n",
    "    return jieba.lcut(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data.review.apply(pre_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      [很快, 好吃, 味道, 足量, 大]\n",
       "1                                 [没有, 送水, 没有, 送水, 没有, 送水]\n",
       "2                                           [非常, 快, 态度, 好]\n",
       "3                                 [方便快捷, 味道, 可口, 快, 递给, 力]\n",
       "4                                   [菜, 味道, 很棒, 送餐, 很, 及时]\n",
       "                               ...                        \n",
       "11982                   [以前, 几乎, 天天, 吃, 现在, 调料, 什么, 都, 不放]\n",
       "11983    [昨天, 订, 凉皮, 两份, 什么, 调料, 都, 没有, 放, 就, 放, 了, 点, ...\n",
       "11984                                  [凉皮, 太辣, ,, 吃不下, 都]\n",
       "11985                                [本来, 迟到, 了, 还, 自己, 点]\n",
       "11986    [肉夹馍, 不错, 羊肉, 泡馍, 酱肉, 包, 很, 一般, 凉面, 没, 想象, 中, ...\n",
       "Name: review, Length: 11987, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator     # 创建词表工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data):\n",
    "    for text in data:\n",
    "        yield text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(data.review), specials=[\"<pad>\", \"<unk>\"], min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['很快', '好吃', '味道', '足量', '大']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 14, 13, 5228, 114]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(data.review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(len(data)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=11987, step=1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 3168,  8984,  7230,  6565,  8710,  5368,  5727,  3483, 10759,\n",
       "             4860,\n",
       "            ...\n",
       "             3625,  2622, 11514,  3844,   341,  8928,  6757,  8872,  8203,\n",
       "             4401],\n",
       "           dtype='int64', length=9589)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.iloc[data.index[~data.index.isin(train_data.index)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, list(['非常', '快', '态度', '好'])],\n",
       "       [1, list(['方便快捷', '味道', '可口', '快', '递给', '力'])],\n",
       "       [1,\n",
       "        list(['超级', '快', '就', '送到', '了', '这么', '冷', '的', '天气', '骑士', '们', '辛苦', '了', '谢谢你们', '麻辣', '香锅', '依然', '很', '好吃'])],\n",
       "       ...,\n",
       "       [0,\n",
       "        list(['差', '的', '无法形容', '我花', '18', '元', '买', '的', '羊肉汤', '结果', '拿来', '里面', '就', '一块', '肉', '粉丝', '也', '就', '那么', '几根', '从来', '没见', '过', '这么', '坑爹', '的', '商家', '了', '简直', '像', '别人', '吃', '剩下', '的', '给', '我', '送来', '的', '？', '恶心', '的', '要命', '卤蛋', '也', '是', '不', '新鲜', '的', '？', '这个', '好', '在', '没', '几元', '钱', '啊', '等', '倒闭', '吧', '你们'])],\n",
       "       [0,\n",
       "        list(['肉夹馍', '没', '送来', '告诉', '我', '十分钟', '内', '送到', '可是', '二十分钟', '了', '还', '没到'])],\n",
       "       [0, list(['本来', '迟到', '了', '还', '自己', '点'])]], dtype=object)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(_label)\n",
    "        precess_text = torch.tensor(vocab(_text), dtype=torch.int64)\n",
    "        text_list.append(precess_text)\n",
    "    label_list = torch.tensor(label_list)\n",
    "    text_list = torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data.values, batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data.values, batch_size=64, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeding : 把文本映射为一个密集向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeding_dim = 100\n",
    "hidden_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embeding_dim, hidden_size):\n",
    "        super(RNN_Net, self).__init__()\n",
    "        self.em = nn.Embedding(vocab_size, embeding_dim)   \n",
    "        self.conv1 = nn.Conv1d(in_channels=embeding_dim, out_channels=64, kernel_size=7)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64,out_channels=128, kernel_size=7)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(output_size=5)\n",
    "        self.fc1 = nn.Linear(128*5, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.em(inputs)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, 128*5)\n",
    "        x = F.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_Net(vocab_size, embeding_dim, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([1, 2], dtype=torch.float32)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    total_acc, total_count, total_loss, = 0, 0, 0\n",
    "    model.train()\n",
    "    for label, text in dataloader:\n",
    "        predicted_label = model(text)\n",
    "        loss = loss_fn(predicted_label, label)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            total_loss += loss.item()*label.size(0)\n",
    "    return total_loss/total_count, total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count, total_loss, = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, text in dataloader:\n",
    "            predicted_label = model(text)\n",
    "            loss = loss_fn(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            total_loss += loss.item()*label.size(0)\n",
    "    return total_loss/total_count, total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, train_dl, test_dl):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, epoch_acc = train(train_dl)\n",
    "        epoch_test_loss, epoch_test_acc = test(test_dl)\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_acc.append(epoch_acc)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "        template = (\"epoch:{:2d}, train_loss: {:.5f}, train_acc: {:.1f}% ,\" \n",
    "                    \"test_loss: {:.5f}, test_acc: {:.1f}%\")\n",
    "        print(template.format(\n",
    "              epoch, epoch_loss, epoch_acc*100, epoch_test_loss, epoch_test_acc*100))\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return train_loss, test_loss, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.63849, train_acc: 60.5% ,test_loss: 0.54427, test_acc: 78.9%\n",
      "epoch: 1, train_loss: 0.51010, train_acc: 75.1% ,test_loss: 0.55379, test_acc: 71.1%\n",
      "epoch: 2, train_loss: 0.39867, train_acc: 83.8% ,test_loss: 0.40319, test_acc: 83.5%\n",
      "epoch: 3, train_loss: 0.34196, train_acc: 86.7% ,test_loss: 0.45021, test_acc: 84.2%\n",
      "epoch: 4, train_loss: 0.29826, train_acc: 88.8% ,test_loss: 0.40772, test_acc: 83.3%\n",
      "epoch: 5, train_loss: 0.28663, train_acc: 88.6% ,test_loss: 0.39047, test_acc: 87.6%\n",
      "epoch: 6, train_loss: 0.23601, train_acc: 91.1% ,test_loss: 0.44591, test_acc: 83.9%\n",
      "epoch: 7, train_loss: 0.20755, train_acc: 92.2% ,test_loss: 0.48363, test_acc: 88.2%\n",
      "epoch: 8, train_loss: 0.18460, train_acc: 93.5% ,test_loss: 0.65321, test_acc: 86.1%\n",
      "epoch: 9, train_loss: 0.26408, train_acc: 90.5% ,test_loss: 0.62031, test_acc: 65.6%\n",
      "epoch:10, train_loss: 0.22891, train_acc: 90.5% ,test_loss: 0.66760, test_acc: 84.2%\n",
      "epoch:11, train_loss: 0.13704, train_acc: 95.2% ,test_loss: 0.66859, test_acc: 87.5%\n",
      "epoch:12, train_loss: 0.15216, train_acc: 95.6% ,test_loss: 0.67084, test_acc: 66.4%\n",
      "epoch:13, train_loss: 0.23113, train_acc: 90.0% ,test_loss: 0.73081, test_acc: 85.7%\n",
      "epoch:14, train_loss: 0.11184, train_acc: 96.0% ,test_loss: 1.16535, test_acc: 86.2%\n",
      "epoch:15, train_loss: 0.13369, train_acc: 94.5% ,test_loss: 0.96647, test_acc: 84.4%\n",
      "epoch:16, train_loss: 0.11673, train_acc: 96.3% ,test_loss: 1.30952, test_acc: 84.8%\n",
      "epoch:17, train_loss: 0.08136, train_acc: 97.4% ,test_loss: 1.22450, test_acc: 86.4%\n",
      "epoch:18, train_loss: 0.07520, train_acc: 97.7% ,test_loss: 1.14344, test_acc: 84.6%\n",
      "epoch:19, train_loss: 0.07272, train_acc: 97.9% ,test_loss: 1.29267, test_acc: 85.2%\n",
      "epoch:20, train_loss: 0.07274, train_acc: 97.5% ,test_loss: 1.27345, test_acc: 84.8%\n",
      "epoch:21, train_loss: 0.05038, train_acc: 98.4% ,test_loss: 1.42704, test_acc: 84.6%\n",
      "epoch:22, train_loss: 0.04770, train_acc: 98.4% ,test_loss: 1.69616, test_acc: 83.7%\n",
      "epoch:23, train_loss: 0.04579, train_acc: 98.5% ,test_loss: 1.92110, test_acc: 85.8%\n",
      "epoch:24, train_loss: 0.07957, train_acc: 97.7% ,test_loss: 1.91626, test_acc: 85.6%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss, train_acc, test_acc = fit(EPOCHS, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
