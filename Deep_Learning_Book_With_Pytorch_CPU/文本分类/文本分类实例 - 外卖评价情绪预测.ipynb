{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集: 某外卖平台收集的用户评价，正向 4000 条，负向 约 8000 条"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字段说明\n",
    "\n",
    "| 字段 | 说明 |\n",
    "| ---- | ---- |\n",
    "| label | 1 表示正向评论，0 表示负向评论 |\n",
    "| review | 评论内容 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装 jieba 和 pandas\n",
    "\n",
    "     pip install pandas jieba sklearn -i https://pypi.doubanio.com/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.GRU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('waimai_10k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>很快，好吃，味道足，量大</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>没有送水没有送水没有送水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>非常快，态度好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>方便，快捷，味道可口，快递给力</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>菜味道很棒！送餐很及时！</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label           review\n",
       "0      1     很快，好吃，味道足，量大\n",
       "1      1     没有送水没有送水没有送水\n",
       "2      1         非常快，态度好。\n",
       "3      1  方便，快捷，味道可口，快递给力\n",
       "4      1     菜味道很棒！送餐很及时！"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11987 entries, 0 to 11986\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   11987 non-null  int64 \n",
      " 1   review  11987 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 187.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7987\n",
       "1    4000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_text(text):\n",
    "    text = text.replace('！', '').replace('，', '').replace('。', '')\n",
    "    return jieba.lcut(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\guanghua\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.534 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "data['review'] = data.review.apply(pre_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      [很快, 好吃, 味道, 足量, 大]\n",
       "1                                 [没有, 送水, 没有, 送水, 没有, 送水]\n",
       "2                                           [非常, 快, 态度, 好]\n",
       "3                                 [方便快捷, 味道, 可口, 快, 递给, 力]\n",
       "4                                   [菜, 味道, 很棒, 送餐, 很, 及时]\n",
       "                               ...                        \n",
       "11982                   [以前, 几乎, 天天, 吃, 现在, 调料, 什么, 都, 不放]\n",
       "11983    [昨天, 订, 凉皮, 两份, 什么, 调料, 都, 没有, 放, 就, 放, 了, 点, ...\n",
       "11984                                  [凉皮, 太辣, ,, 吃不下, 都]\n",
       "11985                                [本来, 迟到, 了, 还, 自己, 点]\n",
       "11986    [肉夹馍, 不错, 羊肉, 泡馍, 酱肉, 包, 很, 一般, 凉面, 没, 想象, 中, ...\n",
       "Name: review, Length: 11987, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator     # 创建词表工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data):\n",
    "    for text in data:\n",
    "        yield text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(data.review), specials=[\"<pad>\", \"<unk>\"], min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['很快', '好吃', '味道', '足量', '大']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 14, 13, 5228, 114]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(data.review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(len(data)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=11987, step=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  392,  1105,  8297,  1976,  8521,  2179,   689,  2716,  9566,\n",
       "             3510,\n",
       "            ...\n",
       "             1387,  7721,  6657,  5624,  1640,   955, 11862,  6361,  4117,\n",
       "              453],\n",
       "           dtype='int64', length=9589)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.iloc[data.index[~data.index.isin(train_data.index)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1,\n",
       "        list(['超级', '快', '就', '送到', '了', '这么', '冷', '的', '天气', '骑士', '们', '辛苦', '了', '谢谢你们', '麻辣', '香锅', '依然', '很', '好吃'])],\n",
       "       [1,\n",
       "        list(['经过', '上次', '晚', '了', '2', '小时', '这次', '超级', '快', '20', '分钟', '就', '送到', '了', '…', '…'])],\n",
       "       [1, list(['味道', '好', '送', '餐快', '分量', '足'])],\n",
       "       ...,\n",
       "       [0, list(['谢谢', '速度', '很快', '辛苦', '了'])],\n",
       "       [0,\n",
       "        list(['外送员', '很', '赞', '商家', '能', '不能', '仔细', '看', '订单', '啊', '点', '的', '干', '拌面', '送来', '的', '是', '汤面', '说', '了', '粉', '汤', '羊血要', '多加', '辣椒', '送来', '的', '一点儿', '辣', '没有'])],\n",
       "       [0, list(['肉夹馍', '肉太少'])]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(_label)\n",
    "        precess_text = torch.tensor(vocab(_text), dtype=torch.int64)\n",
    "        text_list.append(precess_text)\n",
    "    label_list = torch.tensor(label_list)\n",
    "    text_list = torch.nn.utils.rnn.pad_sequence(text_list)\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data.values, batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data.values, batch_size=64, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeding : 把文本映射为一个密集向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeding_dim = 100\n",
    "hidden_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIRNN_Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embeding_dim, hidden_size):\n",
    "        super(RNN_Net, self).__init__()\n",
    "        self.em = nn.Embedding(vocab_size, embeding_dim)   \n",
    "        self.rnn = nn.LSTM(embeding_dim, hidden_size, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_size*2, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.em(inputs)\n",
    "        x = F.dropout(x)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = F.dropout(F.relu(self.fc1(x[-1])))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_Net(vocab_size, embeding_dim, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.5, 0.5), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    total_acc, total_count, total_loss, = 0, 0, 0\n",
    "    model.train()\n",
    "    for label, text in dataloader:\n",
    "        predicted_label = model(text)\n",
    "        loss = loss_fn(predicted_label, label)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            total_loss += loss.item()*label.size(0)\n",
    "    return total_loss/total_count, total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count, total_loss, = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, text in dataloader:\n",
    "            predicted_label = model(text)\n",
    "            loss = loss_fn(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            total_loss += loss.item()*label.size(0)\n",
    "    return total_loss/total_count, total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, train_dl, test_dl):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, epoch_acc = train(train_dl)\n",
    "        epoch_test_loss, epoch_test_acc = test(test_dl)\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_acc.append(epoch_acc)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "        template = (\"epoch:{:2d}, train_loss: {:.5f}, train_acc: {:.1f}% ,\" \n",
    "                    \"test_loss: {:.5f}, test_acc: {:.1f}%\")\n",
    "        print(template.format(\n",
    "              epoch, epoch_loss, epoch_acc*100, epoch_test_loss, epoch_test_acc*100))\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return train_loss, test_loss, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([61, 64, 400])\n",
      "torch.Size([90, 64, 400])\n",
      "torch.Size([92, 64, 400])\n",
      "torch.Size([61, 64, 400])\n",
      "torch.Size([59, 64, 400])\n",
      "torch.Size([78, 64, 400])\n",
      "torch.Size([92, 64, 400])\n",
      "torch.Size([46, 64, 400])\n",
      "torch.Size([53, 64, 400])\n",
      "torch.Size([153, 64, 400])\n",
      "torch.Size([84, 64, 400])\n",
      "torch.Size([47, 64, 400])\n",
      "torch.Size([62, 64, 400])\n",
      "torch.Size([47, 64, 400])\n",
      "torch.Size([85, 64, 400])\n",
      "torch.Size([43, 64, 400])\n",
      "torch.Size([57, 64, 400])\n",
      "torch.Size([61, 64, 400])\n",
      "torch.Size([151, 64, 400])\n",
      "torch.Size([60, 64, 400])\n",
      "torch.Size([37, 64, 400])\n",
      "torch.Size([66, 64, 400])\n",
      "torch.Size([84, 64, 400])\n",
      "torch.Size([62, 64, 400])\n",
      "torch.Size([81, 64, 400])\n",
      "torch.Size([80, 64, 400])\n",
      "torch.Size([112, 64, 400])\n",
      "torch.Size([87, 64, 400])\n",
      "torch.Size([67, 64, 400])\n",
      "torch.Size([51, 64, 400])\n",
      "torch.Size([65, 64, 400])\n",
      "torch.Size([63, 64, 400])\n",
      "torch.Size([90, 64, 400])\n",
      "torch.Size([68, 64, 400])\n",
      "torch.Size([74, 64, 400])\n",
      "torch.Size([52, 64, 400])\n",
      "torch.Size([51, 64, 400])\n",
      "torch.Size([163, 64, 400])\n",
      "torch.Size([61, 64, 400])\n",
      "torch.Size([241, 64, 400])\n",
      "torch.Size([54, 64, 400])\n",
      "torch.Size([58, 64, 400])\n",
      "torch.Size([92, 64, 400])\n",
      "torch.Size([78, 64, 400])\n",
      "torch.Size([59, 64, 400])\n",
      "torch.Size([60, 64, 400])\n",
      "torch.Size([55, 64, 400])\n",
      "torch.Size([80, 64, 400])\n",
      "torch.Size([83, 64, 400])\n",
      "torch.Size([72, 64, 400])\n",
      "torch.Size([47, 64, 400])\n",
      "torch.Size([65, 64, 400])\n",
      "torch.Size([64, 64, 400])\n",
      "torch.Size([77, 64, 400])\n",
      "torch.Size([47, 64, 400])\n",
      "torch.Size([33, 64, 400])\n",
      "torch.Size([48, 64, 400])\n",
      "torch.Size([61, 64, 400])\n",
      "torch.Size([136, 64, 400])\n",
      "torch.Size([43, 64, 400])\n",
      "torch.Size([104, 64, 400])\n",
      "torch.Size([88, 64, 400])\n",
      "torch.Size([73, 64, 400])\n",
      "torch.Size([107, 64, 400])\n",
      "torch.Size([102, 64, 400])\n",
      "torch.Size([96, 64, 400])\n",
      "torch.Size([62, 64, 400])\n",
      "torch.Size([72, 64, 400])\n",
      "torch.Size([55, 64, 400])\n",
      "torch.Size([55, 64, 400])\n",
      "torch.Size([67, 64, 400])\n",
      "torch.Size([65, 64, 400])\n",
      "torch.Size([54, 64, 400])\n",
      "torch.Size([106, 64, 400])\n",
      "torch.Size([65, 64, 400])\n",
      "torch.Size([38, 64, 400])\n",
      "torch.Size([95, 64, 400])\n",
      "torch.Size([114, 64, 400])\n",
      "torch.Size([48, 64, 400])\n",
      "torch.Size([49, 64, 400])\n",
      "torch.Size([51, 64, 400])\n",
      "torch.Size([65, 64, 400])\n",
      "torch.Size([64, 64, 400])\n",
      "torch.Size([113, 64, 400])\n",
      "torch.Size([92, 64, 400])\n",
      "torch.Size([81, 64, 400])\n",
      "torch.Size([55, 64, 400])\n",
      "torch.Size([55, 64, 400])\n",
      "torch.Size([90, 64, 400])\n",
      "torch.Size([80, 64, 400])\n",
      "torch.Size([111, 64, 400])\n",
      "torch.Size([58, 64, 400])\n",
      "torch.Size([149, 64, 400])\n",
      "torch.Size([46, 64, 400])\n",
      "torch.Size([38, 64, 400])\n",
      "torch.Size([101, 64, 400])\n",
      "torch.Size([54, 64, 400])\n",
      "torch.Size([53, 64, 400])\n",
      "torch.Size([279, 64, 400])\n",
      "torch.Size([105, 64, 400])\n",
      "torch.Size([63, 64, 400])\n",
      "torch.Size([88, 64, 400])\n",
      "torch.Size([63, 64, 400])\n",
      "torch.Size([53, 64, 400])\n",
      "torch.Size([68, 64, 400])\n",
      "torch.Size([49, 64, 400])\n",
      "torch.Size([65, 64, 400])\n",
      "torch.Size([96, 64, 400])\n",
      "torch.Size([122, 64, 400])\n",
      "torch.Size([83, 64, 400])\n",
      "torch.Size([94, 64, 400])\n",
      "torch.Size([52, 64, 400])\n",
      "torch.Size([79, 64, 400])\n",
      "torch.Size([42, 64, 400])\n",
      "torch.Size([41, 64, 400])\n",
      "torch.Size([88, 64, 400])\n",
      "torch.Size([43, 64, 400])\n",
      "torch.Size([48, 64, 400])\n",
      "torch.Size([63, 64, 400])\n",
      "torch.Size([56, 64, 400])\n",
      "torch.Size([64, 64, 400])\n",
      "torch.Size([98, 64, 400])\n",
      "torch.Size([109, 64, 400])\n",
      "torch.Size([37, 64, 400])\n",
      "torch.Size([59, 64, 400])\n",
      "torch.Size([71, 64, 400])\n",
      "torch.Size([87, 64, 400])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-703f2bb91dc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-e9f45c38d623>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, train_dl, test_dl)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mepoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mepoch_test_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_test_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-d523e2187352>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch19gpu\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch19gpu\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, test_loss, train_acc, test_acc = fit(EPOCHS, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.5, 0.5), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss, train_acc, test_acc = fit(EPOCHS, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss, train_acc, test_acc = fit(EPOCHS, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
